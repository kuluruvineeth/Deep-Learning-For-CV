{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Scaling Image Pixel Data with Keras"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. MNIST Handwritten Image Classification Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<frozen importlib._bootstrap>:219: RuntimeWarning: numpy.ufunc size changed, may indicate binary incompatibility. Expected 192 from C header, got 216 from PyObject\n",
      "<frozen importlib._bootstrap>:219: RuntimeWarning: numpy.ufunc size changed, may indicate binary incompatibility. Expected 192 from C header, got 216 from PyObject\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train (60000, 28, 28) (60000,)\n",
      "Test ((10000, 28, 28), (10000,))\n",
      "Train 0 255 33.318421449829934 78.56748998339798\n",
      "Test 0 255 33.791224489795916 79.17246322228644\n"
     ]
    }
   ],
   "source": [
    "# load and summarize the MNIST dataset\n",
    "from keras.datasets import mnist\n",
    "# load dataset\n",
    "(train_images,train_labels), (test_images,test_labels) = mnist.load_data()\n",
    "# summarize dataset shape\n",
    "print('Train',train_images.shape,train_labels.shape)\n",
    "print('Test',(test_images.shape,test_labels.shape))\n",
    "# summarize pixel values\n",
    "print('Train',train_images.min(),train_images.max(),train_images.mean(),train_images.std())\n",
    "print('Test',test_images.min(),test_images.max(),test_images.mean(),test_images.std())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Normalizing Images with ImageDataGenerator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train min=0.000, max=255.000\n",
      "Test min=0.000, max=255.000\n",
      "Batches train=938, test=157\n",
      "Batch shape=(64, 28, 28, 1),min=0.000,max=1.000\n"
     ]
    }
   ],
   "source": [
    "# example of normalizing a image dataset\n",
    "from keras.datasets import mnist\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "# load dataset\n",
    "(trainX,trainY), (testX,testY) = mnist.load_data()\n",
    "# reshape dataset to have a single channel\n",
    "width,height,channels = trainX.shape[1],trainX.shape[2],1\n",
    "trainX = trainX.reshape((trainX.shape[0],width,height,channels))\n",
    "testX = testX.reshape((testX.shape[0],width,height,channels))\n",
    "# confirm scale of pixels\n",
    "print('Train min=%.3f, max=%.3f' %(trainX.min(),trainX.max()))\n",
    "print('Test min=%.3f, max=%.3f' %(testX.min(),testX.max()))\n",
    "# create generator \n",
    "datagen = ImageDataGenerator(rescale=1.0/255.0)\n",
    "# prepare iterators to scale images\n",
    "train_iterator = datagen.flow(trainX,trainY,batch_size=64)\n",
    "test_iterator = datagen.flow(testX,testY,batch_size=64)\n",
    "print('Batches train=%d, test=%d' %(len(train_iterator),len(test_iterator)))\n",
    "# confirm the scaling works\n",
    "batchX,batchy = train_iterator.next()\n",
    "print('Batch shape=%s,min=%.3f,max=%.3f' %(batchX.shape,batchX.min(),batchX.max()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Centering Images with ImageDataGenerator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Means train=33.318,test=33.791\n",
      "Data Generator Mean: 33.318\n",
      "(64, 28, 28, 1) 0.8550609\n",
      "(60000, 28, 28, 1) -1.9512918e-05\n"
     ]
    }
   ],
   "source": [
    "# example of centering a image dataset\n",
    "from keras.datasets import mnist\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "# load dataset\n",
    "(trainX,trainy),(testX,testy) = mnist.load_data()\n",
    "# reshape dataset to have a single channel\n",
    "width,height,channels = trainX.shape[1],trainX.shape[2],1\n",
    "trainX = trainX.reshape((trainX.shape[0],width,height,channels))\n",
    "testX = testX.reshape((testX.shape[0],width,height,channels))\n",
    "# report per-image mean\n",
    "print('Means train=%.3f,test=%.3f' %(trainX.mean(),testX.mean()))\n",
    "# create generator that centers pixel values\n",
    "datagen = ImageDataGenerator(featurewise_center=True)\n",
    "# calculate the mean on the training dataset\n",
    "datagen.fit(trainX)\n",
    "print('Data Generator Mean: %.3f' %datagen.mean)\n",
    "# demonstrate effect on a single batch of samples\n",
    "iterator = datagen.flow(trainX,trainy,batch_size=64)\n",
    "# get a batch\n",
    "batchX,batchy = iterator.next()\n",
    "# mean pixel value in the batch\n",
    "print(batchX.shape,batchX.mean())\n",
    "# demonstrate effect on entire training dataset\n",
    "iterator = datagen.flow(trainX,trainy,batch_size=len(trainX),shuffle=False)\n",
    "# get a batch\n",
    "batchX,batchy = iterator.next()\n",
    "# mean pixel value in the batch\n",
    "print(batchX.shape,batchX.mean())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Standardizing Images with ImageDataGenerator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Statistics train=33.318 (78.567), test=33.791 (79.172)\n",
      "Data Generator mean=33.318, std=78.567\n",
      "(64, 28, 28, 1) 4.9375 0.9960977\n",
      "(60000, 28, 28, 1) -3.4560264e-07 0.9999998\n"
     ]
    }
   ],
   "source": [
    "# example of standardizing a image dataset\n",
    "from keras.datasets import mnist\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "# load dataset\n",
    "(trainX,trainy), (testX,testy) = mnist.load_data()\n",
    "# reshape dataset to have a single channel\n",
    "width,height,channels = trainX.shape[1],trainX.shape[2],1\n",
    "trainX = trainX.reshape((trainX.shape[0],width,height,channels))\n",
    "testX = testX.reshape((testX.shape[0],width,height,channels))\n",
    "# report pixel means and standard deviations\n",
    "print('Statistics train=%.3f (%.3f), test=%.3f (%.3f)' %(trainX.mean(),trainX.std(),testX.mean(),testX.std()))\n",
    "# create generator that centers pixel values\n",
    "datagen = ImageDataGenerator(featurewise_center=True,featurewise_std_normalization=True)\n",
    "# calculate the mean on the training dataset\n",
    "datagen.fit(trainX)\n",
    "print('Data Generator mean=%.3f, std=%.3f' %(datagen.mean,datagen.std))\n",
    "# demonstrate effect on a single batch of samples\n",
    "iterator = datagen.flow(trainX,trainy,batch_size=64)\n",
    "# get a batch\n",
    "batchX,batchy = iterator.next()\n",
    "# pixel stats in the batch\n",
    "print(batchX.shape,batchy.mean(),batchX.std())\n",
    "# demonstrate effect on entire training dataset\n",
    "iterator = datagen.flow(trainX,trainy,batch_size=len(trainX),shuffle=False)\n",
    "# get a batch\n",
    "batchX,batchy = iterator.next()\n",
    "# pixel stats in the batch\n",
    "print(batchX.shape,batchX.mean(),batchX.std())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
